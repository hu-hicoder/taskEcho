import 'dart:io';
import 'package:flutter_gemma_embedder/flutter_gemma_embedder.dart';
import 'package:path_provider/path_provider.dart';
import 'i_semantic_search_service.dart';

/// EmbeddingGemma ã‚’ä½¿ç”¨ã—ãŸã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹
/// 
/// Google ã® EmbeddingGemma 300M ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€
/// ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ã§ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
class GemmaEmbedderService implements ISemanticSearchService {
  EmbeddingModel? _model;
  bool _isInitialized = false;

  // ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
  static const String MODEL_FILENAME = 'embeddinggemma-300M_seq512_mixed-precision.tflite';
  static const int EMBEDDING_DIMENSIONS = 768;
  static const EmbeddingModelType MODEL_TYPE = EmbeddingModelType.embeddingGemma300M;
  static const EmbeddingTaskType TASK_TYPE = EmbeddingTaskType.retrieval;
  static const PreferredBackend BACKEND = PreferredBackend.gpu;

  @override
  bool get isInitialized => _isInitialized;

  /// EmbeddingGemma ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
  @override
  Future<void> initialize() async {
    if (_isInitialized) {
      print('âœ… GemmaEmbedder is already initialized');
      return;
    }

    try {
      print('ğŸš€ Initializing EmbeddingGemma...');

      // ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
      final modelPath = await _getModelPath();
      
      // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
      final modelFile = File(modelPath);
      if (!await modelFile.exists()) {
        throw Exception('Model file not found at: $modelPath\n'
            'Please download the EmbeddingGemma model first.');
      }

      print('âœ“ Model file found: $modelPath');
      final fileSize = await modelFile.length();
      print('âœ“ Model size: ${(fileSize / (1024 * 1024)).toStringAsFixed(2)} MB');

      // FlutterGemmaEmbedder ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
      final embedder = FlutterGemmaEmbedder.instance;

      // ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
      _model = await embedder.createModel(
        modelPath: modelPath,
        modelType: MODEL_TYPE,
        dimensions: EMBEDDING_DIMENSIONS,
        taskType: TASK_TYPE,
        backend: BACKEND,
      );
      print('âœ“ EmbeddingModel created');

      // ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
      await _model!.initialize();
      print('âœ“ Model initialized');

      _isInitialized = true;
      print('âœ… EmbeddingGemma initialized successfully!');
      print('   - Model: EmbeddingGemma 300M (seq512)');
      print('   - Dimensions: $EMBEDDING_DIMENSIONS');
      print('   - Backend: ${BACKEND == PreferredBackend.gpu ? "GPU" : "CPU"}');
      print('   - Task: Retrieval (Semantic Search)');
    } catch (e, stackTrace) {
      print('âŒ Error initializing EmbeddingGemma: $e');
      print('Stack trace: $stackTrace');
      _isInitialized = false;
      rethrow;
    }
  }

  /// ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—
  Future<String> _getModelPath() async {
    final directory = await getApplicationDocumentsDirectory();
    return '${directory.path}/$MODEL_FILENAME';
  }

  /// ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã«å¤‰æ›
  @override
  Future<List<double>> embed(String text) async {
    if (!_isInitialized || _model == null) {
      throw Exception('GemmaEmbedder not initialized. Call initialize() first.');
    }

    if (text.isEmpty) {
      throw ArgumentError('Text cannot be empty');
    }

    try {
      // EmbeddingGemma ã¯è‡ªå‹•çš„ã«ã‚¿ã‚¹ã‚¯ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ ã—ã¾ã™
      // "Represent this sentence for searching relevant passages: {text}"
      final embedding = await _model!.encode(text);
      
      if (embedding.isEmpty) {
        throw Exception('Failed to generate embedding: empty result');
      }

      return embedding;
    } catch (e) {
      print('âŒ Error embedding text: $e');
      rethrow;
    }
  }

  /// è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€æ‹¬ã§ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã«å¤‰æ›
  Future<List<List<double>>> batchEmbed(List<String> texts) async {
    if (!_isInitialized || _model == null) {
      throw Exception('GemmaEmbedder not initialized. Call initialize() first.');
    }

    if (texts.isEmpty) {
      throw ArgumentError('Texts list cannot be empty');
    }

    try {
      final embeddings = await _model!.batchEncode(texts);
      return embeddings;
    } catch (e) {
      print('âŒ Error batch embedding texts: $e');
      rethrow;
    }
  }

  /// 2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
  @override
  Future<double> calculateSimilarity(String text1, String text2) async {
    if (!_isInitialized || _model == null) {
      throw Exception('GemmaEmbedder not initialized. Call initialize() first.');
    }

    try {
      // ä¸¡æ–¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã«å¤‰æ›
      final embedding1 = await embed(text1);
      final embedding2 = await embed(text2);

      // ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
      final similarity = _model!.cosineSimilarity(embedding1, embedding2);
      
      return similarity;
    } catch (e) {
      print('âŒ Error calculating similarity: $e');
      rethrow;
    }
  }

  /// ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã¨ãƒ†ã‚­ã‚¹ãƒˆã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
  /// æœ€ã‚‚é¡ä¼¼åº¦ãŒé«˜ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®ã‚¹ã‚³ã‚¢ã‚’è¿”ã™
  @override
  Future<double> calculateKeywordSimilarity(
    String text,
    List<String> keywords,
  ) async {
    if (keywords.isEmpty) {
      return 0.0;
    }

    try {
      // ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆ
      final textEmbedding = await embed(text);

      // å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
      double maxSimilarity = 0.0;
      for (final keyword in keywords) {
        final keywordEmbedding = await embed(keyword);
        final similarity = _model!.cosineSimilarity(textEmbedding, keywordEmbedding);
        
        if (similarity > maxSimilarity) {
          maxSimilarity = similarity;
        }
      }

      return maxSimilarity;
    } catch (e) {
      print('âŒ Error calculating keyword similarity: $e');
      return 0.0;
    }
  }

  /// ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾
  @override
  Future<void> dispose() async {
    try {
      _model?.dispose();
      _model = null;
      _isInitialized = false;
      print('âœ… GemmaEmbedder disposed');
    } catch (e) {
      print('âŒ Error disposing GemmaEmbedder: $e');
    }
  }

  /// ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
  Future<Map<String, dynamic>> getModelInfo() async {
    return {
      'initialized': _isInitialized,
      'modelType': 'EmbeddingGemma 300M',
      'sequenceLength': 512,
      'dimensions': EMBEDDING_DIMENSIONS,
      'backend': BACKEND == PreferredBackend.gpu ? 'GPU' : 'CPU',
      'taskType': 'Retrieval',
      'modelFile': MODEL_FILENAME,
    };
  }
}
